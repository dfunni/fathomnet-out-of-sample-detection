{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from utils.utils import remap, cats_to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inference_df(input_path='../runs/detect/predict/labels/', conf_threshold=0.25):\n",
    "    '''Generates dataframe of information from infrence output files.\n",
    "    Args:\n",
    "        input_path: (string) path to prediction labels files\n",
    "        conf_thrreshold: (float) minimum confidence threshold for valid detection\n",
    "    Returns:\n",
    "        df: (pd.DataFrame) dataframe of inference output\n",
    "    '''\n",
    "    out = {}\n",
    "    filelist = glob.glob(input_path + '*.txt')\n",
    "\n",
    "    cat_df = pd.read_json('../category_key.json')\n",
    "    shallow = cat_df[cat_df.shallow_species == True]['index'].to_list()\n",
    "    mapper = cat_df[['id', 'index']].to_dict()['id']\n",
    "\n",
    "    for i, file in enumerate(filelist):\n",
    "        with open(file, 'r') as f:\n",
    "\n",
    "            cats = []\n",
    "            conf = []\n",
    "            location = []\n",
    "            weak_shallow = 0\n",
    "            strong_shallow = 0\n",
    "            no_detection = 0\n",
    "\n",
    "            for line in f.readlines():\n",
    "\n",
    "                category, x, y, w, h, conf_value = line.split(' ')\n",
    "                category = int(category)\n",
    "                conf_value = float(conf_value)\n",
    "                loc = tuple([float(i) for i in [x, y, w, h]])\n",
    "\n",
    "                if category in shallow:\n",
    "                    weak_shallow = 1    # weakly shallow if there is a shallow detection at any confidence\n",
    "                    if conf_value >= conf_threshold:\n",
    "                        strong_shallow = 1  # strongly shallow if a high conf shallow detection\n",
    "\n",
    "                if (category not in cats) and (conf_value >= conf_threshold): # dedup and add to list\n",
    "                    cats.append(category)\n",
    "                    conf.append(conf_value)\n",
    "                    location.append(loc)\n",
    "            \n",
    "            cats = remap(cats, mapper)\n",
    "\n",
    "            if len(cats) == 0:\n",
    "                no_detection = 1\n",
    "\n",
    "        out[i] = {'id': os.path.basename(file)[:-4],\n",
    "                  'categories': cats,\n",
    "                  'location': location,\n",
    "                  'conf': conf,\n",
    "                  'weak_shallow': weak_shallow,\n",
    "                  'strong_shallow': strong_shallow,\n",
    "                  'no_detection': no_detection,\n",
    "                  #   'osd': osd,\n",
    "                  }\n",
    "\n",
    "    df = pd.DataFrame.from_dict(out, orient='index')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_json('../supercat_key.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_json('../category_key.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = pd.read_json('../category_key.json')\n",
    "shallow = cat_df[cat_df.shallow_species == True]['id'].to_list()\n",
    "shallow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inference_df_sup(input_path='../runs/detect/predict_superL/labels/', conf_threshold=0.15):\n",
    "    '''Generates dataframe of information from infrence output files.\n",
    "    Args:\n",
    "        input_path: (string) path to prediction labels files\n",
    "        conf_thrreshold: (float) minimum confidence threshold for valid detection\n",
    "    Returns:\n",
    "        df: (pd.DataFrame) dataframe of inference output\n",
    "    '''\n",
    "    out = {}\n",
    "    filelist = glob.glob(input_path + '*.txt')\n",
    "\n",
    "    cat_df = pd.read_json('../category_key.json')\n",
    "    scat_df = pd.read_json('../supercat_key.json')\n",
    "    shallow = cat_df[cat_df.shallow_species == True]['id'].to_list()\n",
    "    mapper = scat_df[['top_category_id', 'supercat_id']].to_dict()['top_category_id']\n",
    "    mapper = {str(k): mapper[k] for k in mapper.keys()}\n",
    "\n",
    "    for i, file in enumerate(filelist):\n",
    "        with open(file, 'r') as f:\n",
    "\n",
    "            cats = []\n",
    "            supercats = []\n",
    "            conf = []\n",
    "            location = []\n",
    "            weak_shallow = 0\n",
    "            strong_shallow = 0\n",
    "            no_detection = 0\n",
    "\n",
    "            for line in f.readlines():\n",
    "\n",
    "                supercat, x, y, w, h, conf_value = line.split(' ')\n",
    "                category = remap(supercat, mapper)[0]\n",
    "                supercat = int(supercat)\n",
    "                conf_value = float(conf_value)\n",
    "                loc = tuple([float(i) for i in [x, y, w, h]])\n",
    "\n",
    "                if category in shallow:\n",
    "                    weak_shallow = 1    # weakly shallow if there is a shallow detection at any confidence\n",
    "                    if conf_value >= conf_threshold:\n",
    "                        strong_shallow = 1  # strongly shallow if a high conf shallow detection\n",
    "\n",
    "                if (category not in cats) and (conf_value >= conf_threshold): # dedup and add to list\n",
    "                    cats.append(category)\n",
    "                    supercats.append(supercat)\n",
    "                    conf.append(conf_value)\n",
    "                    location.append(loc)\n",
    "            \n",
    "\n",
    "            if len(cats) == 0:\n",
    "                no_detection = 1\n",
    "\n",
    "        out[i] = {'id': os.path.basename(file)[:-4],\n",
    "                  'supercategory': supercats,\n",
    "                  'categories_s': cats,\n",
    "                  'location_s': location,\n",
    "                  'conf_s': conf,\n",
    "                  'weak_shallow_s': weak_shallow,\n",
    "                  'strong_shallow_s': strong_shallow,\n",
    "                  'no_detection_s': no_detection\n",
    "                  }\n",
    "\n",
    "    df = pd.DataFrame.from_dict(out, orient='index')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sup = generate_inference_df_sup(conf_threshold=0.25)\n",
    "df_sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = generate_inference_df('../runs/detect/predict40m/labels/', 0.5)\n",
    "df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_cat.merge(df_sup, on='id')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_osd(row):\n",
    "    shallow = (row.strong_shallow, row.strong_shallow_s, row.weak_shallow, row.weak_shallow_s)\n",
    "    # no detections from either model - must be osd\n",
    "    if row.no_detection and row.no_detection_s:\n",
    "        row['osd'] = 1.0\n",
    "        row['categories'] = [52] # setting to the most common deep object\n",
    "\n",
    "    if row.no_detection and not row.no_detection_s:\n",
    "        row['categories'] = row.categories_s\n",
    "    # nothing detected by cat, something detected by super\n",
    "    if shallow == (0,0,0,0):\n",
    "        row['osd'] = 0.9\n",
    "    if shallow == (0,0,0,1):\n",
    "        row['osd'] = 0.7\n",
    "    if shallow == (0,1,0,1):\n",
    "        row['osd'] = 0.5\n",
    "    \n",
    "    if shallow == (0,0,1,0):\n",
    "        row['osd'] = 0.4\n",
    "    if shallow == (0,1,0,1):\n",
    "        row['osd'] = 0.4\n",
    "    if shallow == (0,0,1,1):\n",
    "        row['osd'] = 0.3\n",
    "    if shallow == (1,0,1,0):\n",
    "        row['osd'] = 0.2\n",
    "    if shallow == (0,1,1,1):\n",
    "        row['osd'] = 0.1\n",
    "    if shallow == (1,0,1,1):\n",
    "        row['osd'] = 0.1\n",
    "    if shallow == (1,1,1,1):\n",
    "        row['osd'] = 0.0\n",
    "        \n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = df.apply(detect_osd, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df[out_df['osd'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top(lst):\n",
    "    return f'[{lst[0]}]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_cat(lst):\n",
    "    if len(lst) == 1:\n",
    "        return f'[{lst[0]}]'\n",
    "    else:\n",
    "        return ' '.join([str(x) for x in lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out_df[['id', 'categories', 'osd']].copy()\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out.categories = out.categories.apply(select_top)\n",
    "out.categories = out.categories.apply(format_cat)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv('../submissions/submission_27.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.isnull().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_json('runs/predict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_json('../runs/predict133m.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_json('../runs/predict40m.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
