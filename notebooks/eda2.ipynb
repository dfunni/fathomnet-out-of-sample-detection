{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd\n",
    "import yaml\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../object_detection/train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m coco \u001b[39m=\u001b[39m COCO(\u001b[39m\"\u001b[39;49m\u001b[39m../object_detection/train.json\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m coco_eval \u001b[39m=\u001b[39m COCO(\u001b[39m\"\u001b[39m\u001b[39m../object_detection/eval.json\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pycocotools/coco.py:81\u001b[0m, in \u001b[0;36mCOCO.__init__\u001b[0;34m(self, annotation_file)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mloading annotations into memory...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     80\u001b[0m tic \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 81\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(annotation_file, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     82\u001b[0m     dataset \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m     83\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mtype\u001b[39m(dataset)\u001b[39m==\u001b[39m\u001b[39mdict\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mannotation file format \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m not supported\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(dataset))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../object_detection/train.json'"
     ]
    }
   ],
   "source": [
    "coco = COCO(\"../object_detection/train.json\")\n",
    "coco_eval = COCO(\"../object_detection/eval.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = pd.DataFrame.from_dict(coco.cats, orient='index')\n",
    "ann_df = pd.DataFrame.from_dict(coco.anns, orient='index')\n",
    "train_img_df = pd.DataFrame.from_dict(coco.imgs, orient='index')\n",
    "eval_img_df = pd.DataFrame.from_dict(coco_eval.imgs, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_eda(image_df):\n",
    "    n_total = len(image_df)\n",
    "    dims = pd.Series(tuple(zip(image_df.width, image_df.height)))\n",
    "    print(f'Total number of images in dataset: {n_total}')\n",
    "    print('Top resolutions:')\n",
    "    print(dims.value_counts().head(25))\n",
    "\n",
    "# images_eda(train_img_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_eda(annotation_df, categories_df):\n",
    "    cat_count = annotation_df.category_id.value_counts().to_frame()\n",
    "    df = categories_df.join(cat_count).sort_values('category_id', ascending=False).reset_index(drop=True)\n",
    "    df = df.rename(columns={'id': 'category_id',\n",
    "                              'name': 'category',\n",
    "                              'supercategory': 'supercategory',\n",
    "                              'category_id': 'cat_id_counts'})\n",
    "    # df = df[df.cat_id_counts > 50]\n",
    "    print(f'There are {len(df.dropna())} of 290 species present in the dataset.')\n",
    "    print(f'There are {len(df.dropna().supercategory.unique())} of 20 semantic supercategories present.')\n",
    "    return df\n",
    "\n",
    "df = object_eda(ann_df, cat_df).dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_dict = {}\n",
    "for i, supercat in enumerate(df.supercategory.unique()):\n",
    "    df2 = df[df.supercategory == supercat]\n",
    "    nsup = sum(df2['cat_id_counts'])\n",
    "    \n",
    "    most_common_loc =df2['cat_id_counts'].max()\n",
    "    # print(supercat, nsup, most_common_loc)\n",
    "    most_common = int(df2[df2.cat_id_counts == most_common_loc]['category_id'])\n",
    "    super_dict[i] = {'supercat_id': i,\n",
    "                     'supercategory': supercat,\n",
    "                     'top_category_id': most_common,\n",
    "                     'cat_id_percentage': most_common_loc / nsup}\n",
    "\n",
    "df_super = pd.DataFrame.from_dict(super_dict, orient='index')\n",
    "df_super"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supercat_map = df_super[['supercat_id', 'supercategory']].to_dict()['supercategory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {'path': '/data/dataset',\n",
    "           'train': 'images/train',\n",
    "           'val': 'images/val',\n",
    "           'names': supercat_map}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/data/super_dataset.yaml\", 'w') as yamlfile:\n",
    "    data = yaml.dump(dataset, yamlfile)\n",
    "    print(\"Write successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supertop = df.merge(df_super, on='supercategory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_super.to_json('../supercat_key.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_super_df = ann_df.merge(df_supertop, on='category_id').sort_values('id').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_super_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_out = ann_super_df[['id', 'image_id', 'category_id', 'segmentation', 'area', 'bbox', 'iscrowd']]\n",
    "ann_out = ann_out.assign(category_id=ann_super_df['supercat_id'])\n",
    "ann_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann_out.to_json('../annotation_sup.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann_super_df.to_json('../master_key.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# super_map = {}\n",
    "# for i, cat in enumerate(df.category_id.unique()):\n",
    "#     df2 = df[df.category_id == cat]\n",
    "#     # print(supercat, df[df.supercategory == supercat]['category_id'].unique())\n",
    "#     super_map[cat] = df2.supercategory.values\n",
    "# super_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supercat_eda(annotation_df, categories_df):\n",
    "    df = categories_df\n",
    "    out = {}\n",
    "    supermap = {i: list(df[df.supercategory == i].id.unique()) for i in df.supercategory.unique()}\n",
    "    for i in supermap.keys():\n",
    "        out[i] = 0\n",
    "        for j in supermap[i]:\n",
    "            out[i] += (len(annotation_df[annotation_df.category_id == j].image_id.unique()))    \n",
    "    return out, supermap\n",
    "\n",
    "supercat_eda(ann_df, cat_df)#.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
